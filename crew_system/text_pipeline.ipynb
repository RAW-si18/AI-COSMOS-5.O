{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import MobileBertTokenizer, MobileBertModel\n",
    "from langdetect import detect\n",
    "import re\n",
    "from typing import List, Dict\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "class TextProcessingPipeline:\n",
    "    def __init__(self, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.device = device\n",
    "        self.tokenizer = MobileBertTokenizer.from_pretrained('google/mobilebert-uncased')\n",
    "        self.model = MobileBertModel.from_pretrained('google/mobilebert-uncased').to(self.device)\n",
    "        self.model.eval()\n",
    "        self.stopwords = set(stopwords.words('english'))\n",
    "\n",
    "    def preprocess_text(self, text: str) -> str:\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        # Remove special characters and digits\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "        # Remove stopwords\n",
    "        tokens = [token for token in tokens if token not in self.stopwords]\n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def detect_language(self, text: str) -> str:\n",
    "        try:\n",
    "            return detect(text)\n",
    "        except:\n",
    "            return 'unknown'\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate_embedding(self, text: str) -> torch.Tensor:\n",
    "        inputs = self.tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        outputs = self.model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).squeeze().cpu()\n",
    "\n",
    "    def process_text(self, text: str) -> Dict:\n",
    "        preprocessed_text = self.preprocess_text(text)\n",
    "        language = self.detect_language(preprocessed_text)\n",
    "        embedding = self.generate_embedding(preprocessed_text)\n",
    "        \n",
    "        return {\n",
    "            'preprocessed_text': preprocessed_text,\n",
    "            'language': language,\n",
    "            'embedding': embedding\n",
    "        }\n",
    "\n",
    "    def process_image_output(self, image_output: Dict) -> Dict:\n",
    "        results = {}\n",
    "        \n",
    "        # Process OCR text\n",
    "        if 'ocr' in image_output:\n",
    "            ocr_text = ' '.join(image_output['ocr'])\n",
    "            results['ocr_processed'] = self.process_text(ocr_text)\n",
    "        \n",
    "        # Process image caption\n",
    "        if 'caption' in image_output:\n",
    "            results['caption_processed'] = self.process_text(image_output['caption'])\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Usage\n",
    "def main():\n",
    "    # Assuming we have the output from the Image Processing Pipeline\n",
    "    image_output = {\n",
    "        'object_detection': [[0, 0, 100, 100, 0.9, 1]],  # Example output\n",
    "        'classification': 5,  # Example class ID\n",
    "        'ocr': ['Hello', 'World'],\n",
    "        'caption': 'A computer screen displaying text'\n",
    "    }\n",
    "\n",
    "    text_pipeline = TextProcessingPipeline()\n",
    "    text_results = text_pipeline.process_image_output(image_output)\n",
    "    \n",
    "    print(\"OCR Processed:\")\n",
    "    print(text_results['ocr_processed'])\n",
    "    print(\"\\nCaption Processed:\")\n",
    "    print(text_results['caption_processed'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
