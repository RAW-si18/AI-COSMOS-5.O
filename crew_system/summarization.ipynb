{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from typing import Dict\n",
    "import numpy as np\n",
    "\n",
    "class SummarizationModule:\n",
    "    def __init__(self, model_name='t5-small', device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.device = device\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "        self.model.eval()\n",
    "\n",
    "        # Optimize model for inference\n",
    "        self.model = torch.jit.script(self.model)  # JIT compilation for faster inference\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate_summary(self, text: str, max_length: int = 150) -> str:\n",
    "        # Prepare input\n",
    "        input_ids = self.tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True).to(self.device)\n",
    "\n",
    "        # Generate summary\n",
    "        summary_ids = self.model.generate(\n",
    "            input_ids,\n",
    "            max_length=max_length,\n",
    "            num_beams=4,\n",
    "            no_repeat_ngram_size=2,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "        # Decode summary\n",
    "        summary = self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        return summary\n",
    "\n",
    "    def process(self, fused_features: np.ndarray, task_routing: Dict[str, float], original_text: str) -> Dict:\n",
    "        summarization_prob = task_routing.get('Summarization', 0)\n",
    "        \n",
    "        if summarization_prob > 0.5:  # Threshold for triggering summarization\n",
    "            summary = self.generate_summary(original_text)\n",
    "            return {\n",
    "                'summary': summary,\n",
    "                'confidence': summarization_prob\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'summary': None,\n",
    "                'confidence': summarization_prob\n",
    "            }\n",
    "\n",
    "class MultimodalProcessor:\n",
    "    def __init__(self, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.device = device\n",
    "        self.fusion_layer = MultimodalFusionLayer().to(device)\n",
    "        self.routing_layer = TaskRoutingLayer().to(device)\n",
    "        self.summarization_module = SummarizationModule(device=device)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def process(self, image_output: Dict, text_output: Dict) -> Dict:\n",
    "        # ... (previous fusion and routing code) ...\n",
    "\n",
    "        # Process with Summarization module\n",
    "        original_text = text_output['ocr_processed']['preprocessed_text'] + ' ' + text_output['caption_processed']['preprocessed_text']\n",
    "        summarization_result = self.summarization_module.process(fused_features.cpu().numpy(), task_routing, original_text)\n",
    "\n",
    "        return {\n",
    "            'fused_features': fused_features.cpu().numpy(),\n",
    "            'task_routing': task_routing,\n",
    "            'summarization': summarization_result\n",
    "        }\n",
    "\n",
    "# Usage\n",
    "def main():\n",
    "    # Simulated outputs from previous pipelines\n",
    "    image_output = {\n",
    "        'object_detection': [[0, 0, 100, 100, 0.9, 1]],\n",
    "        'classification': 5,\n",
    "        'classification_features': [0.1] * 768,  # Simulated feature vector\n",
    "        'ocr': ['Hello', 'World'],\n",
    "        'caption': 'A computer screen displaying text'\n",
    "    }\n",
    "    \n",
    "    text_output = {\n",
    "        'ocr_processed': {\n",
    "            'preprocessed_text': 'hello world',\n",
    "            'language': 'en',\n",
    "            'embedding': torch.randn(512)\n",
    "        },\n",
    "        'caption_processed': {\n",
    "            'preprocessed_text': 'computer screen displaying text',\n",
    "            'language': 'en',\n",
    "            'embedding': torch.randn(512)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    processor = MultimodalProcessor()\n",
    "    result = processor.process(image_output, text_output)\n",
    "    \n",
    "    print(\"Fused Features Shape:\", result['fused_features'].shape)\n",
    "    print(\"\\nTask Routing Probabilities:\")\n",
    "    for task, prob in result['task_routing'].items():\n",
    "        print(f\"{task}: {prob:.4f}\")\n",
    "    \n",
    "    print(\"\\nSummarization Result:\")\n",
    "    print(f\"Confidence: {result['summarization']['confidence']:.4f}\")\n",
    "    if result['summarization']['summary']:\n",
    "        print(f\"Summary: {result['summarization']['summary']}\")\n",
    "    else:\n",
    "        print(\"No summary generated (confidence below threshold)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
